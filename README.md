# **onomatopoeia_captioning**
음성 및 영상 인식을 활용한 실시간 의성어 기반 증강 현실 시스템

## **CO-Authors**
1. 조예원 (팀장. joyewon1212) 
2. 심현화 () 
3. 이다민 (프로그래머, ahrism10M501)
4. 정의현 ()

# **개요**

 기존 AI는 사람의 발소리와 간단한 소리를 영상 하단의 자막으로 표현할 수 있으나, 영상 내 어느 위치에서 어떤 소리가 발생하는지 시각적으로 보여주지는 못한다.    
 
 본 프로젝트는 음성 및 영상 인식 모델을 구축하여 실제로 소리가 발생하는 곳에서 생동감 있는 의성어를 생성하는 것을 목표로 하였다. 이는 청각 장애인의 콘텐츠 소비와 생활을 보조할 수 있다.   

 청각 장애인의 영상 콘텐츠 소비는 자막을 이용하거나 VR 등의 체험형 매체를 활용하는 수준에 머물러 있으며 그중 대다수가 자막을 보고 콘텐츠를 소비한다. 따라서 청각 장애인의 영상 콘텐츠 소비에 있어 자막의 중요성이 높으나, 현재 제공되는 자동 생성 자막의 낮은 정확도는 소비의 질에 영향을 주는 주요 한계점으로 지적된다.   
 
 본 프로젝트는 이러한 자막의 질적 개선을 목표로 하며, 객체에서 발생하는 소리를 의성어로 표현하고 그 위치에 적절한 크기와 애니메이션을 동반한 직관적인 자막을 생성하는 것이다.   
 
 본 프로젝트는 소리의 위치, 생동감, 실제 소리의 표현을 개선하고자 하며, 이를 위해 자막에 애니메이션을 효과를 추가하였다. 다만, 본 프로젝트의 핵심은 의성어를 올바른 위치에 생성하는 것이므로, 애니메이션은 차후 연구를 위한 방향 제시 차원에서 간단하게 구현하였다.   

# **설명**

본 프로젝트는 AI-hub의 공개 데이터셋 이미지 '[사운드 매칭 데이터][데이터 참조 링크]'를 사용하였습니다.   

학습된 데이터는 '국 끓이기, 면 끓이기, 고구마 튀기기, 닭고기 굽기, 냉장고 작동하기, 당근 썰기, 헤어드라이어 작동하기, 사과 썰기, 전기압력밥솥 사용하기, 믹서기 사용 야채 갈기, 전자레인지 작동하기’ 11종 데이터의 3단계 범주 중 차상위 수준에서 분류된 ‘굽기, 끓이기, 냉장고 사용, 드라이어 사용, 믹서기 사용, 썰기, 압력밥솥 사용, 전자레인지 사용, 튀기기’총 9개 클래스 입니다.   

프로젝트에 사용된 모델을 학습하기 위하여 경로는 이러해야합니다.

데이터셋
\
| 오디오셋
| \
| | train
| | \
| | | audio
| | | label
| | 
| | valid
| | \
| | | audio
| | | label
| |
| | test
| | \
| | | audio
| | | label
|
| 비디오셋
| \
| | train
| | \
| | | image
| | | label
| \
| | valid
| | \
| | | image
| | | label
| |
| | test
| | \
| | | image
| | | label


## Audio Model
 프로젝트에 사용된 오디오 모델을 정리한 파일입니다.
 o

 [데이터 참조 링크]: https://www.aihub.or.kr/aihubdata/data/view.do?searchKeyword=%EC%9D%B4%EB%AF%B8%EC%A7%80+%EC%82%AC%EC%9A%B4%EB%93%9C&aihubDataSe=data&dataSetSn=71602
