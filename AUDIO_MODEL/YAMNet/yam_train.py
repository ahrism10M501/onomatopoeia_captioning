import os
import glob
import json

import torch
from torch import nn, optim
from torch.utils.data import Dataset, DataLoader
import torchaudio
from torchaudio.transforms import MelSpectrogram

from tqdm import tqdm

from torch_vggish_yamnet import yamnet
from data_collector import DataCollector

root_path = ''

sound_data = glob.glob(f"{root_path}\\train\\audio\\**\\*.wav", recursive=True)
sound_annot_data = glob.glob(f"{root_path}\\train\\label\\**\\*.json", recursive=True)
val_sound_data = glob.glob(f"{root_path}\\valid\\audio\\**\\*.wav", recursive=True)
val_sound_annot_data = glob.glob(f"{root_path}\\valid\\label\\**\\*.json", recursive=True)

train_data = DataCollector(sound_data, sound_annot_data)
val_data = DataCollector(val_sound_data, val_sound_annot_data)

print(f"Train data size: {len(train_data)}, Valid data size: {len(val_data)}")

class CustomSoundDataset(Dataset):
    def __init__(self, json_wav_pairs, win_length=512, sample_rate=16000, n_mels=128, n_fft=1024, max_len=1000):
        self.data = json_wav_pairs  # ë¦¬ìŠ¤íŠ¸ í˜•íƒœ: [[json_path, [wav_path]], ...]
        self.win_length = win_length
        self.sample_rate = sample_rate
        self.n_mels = n_mels
        self.n_fft = n_fft
        self.max_len = max_len  # ìµœëŒ€ ê¸¸ì´ ì œí•œ

        # MelSpectrogram ë³€í™˜
        self.mel_transform = MelSpectrogram(sample_rate=self.sample_rate, n_mels=self.n_mels, n_fft=self.n_fft, win_length=self.win_length)

        # ë¼ë²¨ ë§¤í•‘ (depth2 ê¸°ì¤€)
        self.labels = sorted(list(set([self._get_label(json_path) for json_path, _ in self.data])))
        self.label_to_idx = {label: i for i, label in enumerate(self.labels)}

    def _get_label(self, json_path):
        with open(json_path, encoding='utf-8') as f:
            meta = json.load(f)
        return meta['info']['class']['depth2']

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        json_path, wav_paths = self.data[idx]
        wav_path = wav_paths[0]

        # ë¼ë²¨ ì¶”ì¶œ
        label_name = self._get_label(json_path)
        label_idx = self.label_to_idx[label_name]
        
        # ì˜¤ë””ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸°
        waveform, sr = torchaudio.load(wav_path)

        # mono ë³€í™˜ (stereo ëŒ€ì‘)
        if waveform.shape[0] > 1:  # 2Dë¼ë©´
            waveform = waveform.mean(dim=0, keepdim=True)

        # MelSpectrogram ë³€í™˜
        mel_spec = self.mel_transform(waveform)  # [1, n_mels, time]

        # íŒ¨ë”©: ìµœëŒ€ ê¸¸ì´ë³´ë‹¤ ì§§ì€ ê²½ìš° íŒ¨ë”©, ê¸´ ê²½ìš° í¬ë¡­
        mel_spec_len = mel_spec.shape[-1]
        if mel_spec_len < self.max_len:
            pad_size = self.max_len - mel_spec_len
            mel_spec = nn.functional.pad(mel_spec, (0, pad_size))  # ë’¤ìª½ì— íŒ¨ë”© ì¶”ê°€
        elif mel_spec_len > self.max_len:
            mel_spec = mel_spec[:, :, :self.max_len]  # ì‹œê°„ ì¶•ì— ëŒ€í•´ì„œ í¬ë¡­

        return mel_spec, label_idx

if __name__=='__main__':
    # ë°ì´í„° ì¤€ë¹„
    from torch.optim.lr_scheduler import CosineAnnealingLR
    from torch.amp import autocast, GradScaler

    with open("yam_hyper_param.json", 'r') as f:
         buff = json.load(f)
    hyper_params = buff["params"]

    train_dataset = CustomSoundDataset(train_data)
    val_dataset = CustomSoundDataset(val_data)
    print(f"Data_class: {train_dataset.label_to_idx}")

    train_dataloader = DataLoader(train_dataset, batch_size=hyper_params["batch"], shuffle=True)
    val_dataloader = DataLoader(val_dataset, batch_size=hyper_params["batch"], shuffle=False)
    # {'êµ½ê¸°': 0, 'ë“ì´ê¸°': 1, 'ëƒ‰ì¥ê³  ì‚¬ìš©': 2, 'ë“œë¼ì´ì–´ ì‚¬ìš©': 3, 'ë¯¹ì„œê¸° ì‚¬ìš©': 4, 'ì°ê¸°': 5, 'ì••ë ¥ë°¥ì†¥ ì‚¬ìš©': 6, 'ì „ìë ˆì¸ì§€ ì‚¬ìš©': 7, 'íŠ€ê¸°ê¸°': 8}
    
    # ëª¨ë¸ ì¤€ë¹„
    model = yamnet.yamnet()
    model.classifier = nn.Linear(in_features=1024, out_features=len(train_dataset.label_to_idx), bias=True)

    try:
        if os.path.exists('yam_best_model.pth'):
            model.load_state_dict(torch.load('yam_best_model.pth'))
            print("yam_best_model.pth loaded")
    except Exception as e:
        print(e)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    device_name = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)
    
    # í•™ìŠµ êµ¬ì„±
    criterion = nn.CrossEntropyLoss(label_smoothing=hyper_params["label_smoothing"])
    optimizer = optim.AdamW(model.parameters(), lr=hyper_params["lr"])
    scheduler = CosineAnnealingLR(optimizer, T_max=hyper_params["epoch"], eta_min=hyper_params["eta_min"])
    scaler = GradScaler(device=device_name)

    num_epoch = hyper_params["epoch"]
    accumulation_steps = hyper_params["accum"]
    best_acc = buff["best_acc"]

    # ğŸ”¸ ê²€ì¦ í•¨ìˆ˜ ì •ì˜
    def evaluate(model, dataloader):
        model.eval()
        total_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for inputs, labels in dataloader:
                inputs, labels = inputs.to(device), labels.to(device)

                embeddings, logits = model(inputs)
                
                loss = criterion(logits, labels)
                total_loss += loss.item()

                _, preds = torch.max(logits, 1)
                correct += (preds == labels).sum().item()
                total += labels.size(0)

        return total_loss / len(dataloader), 100 * correct / total

    # í•™ìŠµ ë£¨í”„
    for epoch in range(num_epoch):
        model.train()
        running_loss = 0.0

        for i, (inputs, labels) in enumerate(tqdm(train_dataloader)):
            inputs, labels = inputs.to(device), labels.to(device)

            with autocast(device_type=device_name):
                embeddings, logits = model(inputs)
                loss = criterion(logits, labels)
                loss = loss / accumulation_steps
            
    
            scaler.scale(loss).backward()

            if (i+1) % accumulation_steps == 0:
                scaler.step(optimizer)
                model.zero_grad()
                scaler.update()
                optimizer.zero_grad()
                running_loss += loss.item() * accumulation_steps

        train_loss = running_loss / len(train_dataloader)

        # ğŸ”¸ validation í‰ê°€
        val_loss, val_acc = evaluate(model, val_dataloader)
        print(f"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.2f}%")
        
        # ğŸ”¸ ëª¨ë¸ ì €ì¥ ì¡°ê±´
        if best_acc < val_acc:
            best_acc = val_acc
            torch.save(model.state_dict(), 'yam_best_model.pth')
            print(f"âœ”ï¸ Best model saved (Val Loss: {val_loss:.4f})")
            
            buff["best_acc"] = val_acc
            with open("yam_hyper_param.json", 'w') as f:
                json.dump(buff, f)

        scheduler.step()

    # ğŸ”¹ ìµœì¢… Train Accuracy ì¶œë ¥
    train_acc_loss, train_acc = evaluate(model, train_dataloader)
    print(f"Train Accuracy: {train_acc:.2f}%")
